{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    dataMat = np.mat([\n",
    "        [1.0,2.1],\n",
    "        [1.5,1.6],\n",
    "        [1.3,1.0],\n",
    "        [1.0,1.0],\n",
    "        [2.0,1.0],\n",
    "    ])\n",
    "    classLabels = [1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return dataMat,classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMTQA2L0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2698f23d160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataMat,classLabels = loadSimpData()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(len(classLabels)):\n",
    "    if classLabels[i] == 1.0:\n",
    "        ax.scatter(dataMat[i,0],dataMat[i,1],marker = 'o',color = 'r')\n",
    "    else:\n",
    "        ax.scatter(dataMat[i,0],dataMat[i,1],marker = 's',color = 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义decision stump 单层决策树\n",
    "def stumpClasify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1)) # 返回划分结果矩阵\n",
    "    # 对应数值数据有两种分类方向\n",
    "    # 对于标称数据有等于和不等两种情况（决策树中的情况）\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0 # 平行于坐标轴的直线为阈值，分类，小于阈值的为-1.0 ，\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0 # 大于阈值的为 -1.0 两种分类方向\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    labelMatrix = np.mat(classLabels).T\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0 # 步数，决定可能的取值情况\n",
    "    bestStump = {}  # 存储最优单层树\n",
    "    bestClassEst = np.mat(np.zeros((m,1))) # 存储最优单层树的分类误差\n",
    "    minError = np.inf # 初始化误差为无穷大\n",
    "    for i in range(n): # 对于每个维度上的特征\n",
    "        rangeMin = dataMatrix[:,i].min()\n",
    "        rangeMax = dataMatrix[:,i].max()\n",
    "        stepSize = (rangeMax - rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1): # 对于每一个可能取值的步长，这里额外处理取值范围之外的点\n",
    "            for inequal in ['lt','gt']: # 对于该取值下的两种不同分类方向\n",
    "                threshVal = rangeMin + j*stepSize # 计算此时的阈值\n",
    "                predictedVals = stumpClasify(dataMatrix,i,threshVal,inequal)\n",
    "                errArr = np.mat(np.ones((m,1))) # 创建一个错误分类项挑选矩阵\n",
    "                errArr[predictedVals == labelMatrix] = 0 # 挑选\n",
    "                # 这里是评估在相同权重D情况下，最优的单层决策树的评估值，\n",
    "                #也是用于更新alpha以及D的错误率\n",
    "                weightedError = D.T*errArr # 计算加权错误？？？ \n",
    "#                 print(\"split: dim %d, thresh %.2f, thresh inequal: %s, the weighted error is %.3f\"%(i,threshVal,inequal,weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: dim 0, thresh 0.90, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 0.90, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.00, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.00, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.10, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.10, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.20, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.20, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.30, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 0, thresh 1.30, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 0, thresh 1.40, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 0, thresh 1.40, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 0, thresh 1.50, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.50, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.60, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.60, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.70, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.70, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.80, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.80, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 1.90, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 0, thresh 1.90, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 0, thresh 2.00, thresh inequal: lt, the weighted error is 0.600\n",
      "split: dim 0, thresh 2.00, thresh inequal: gt, the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 0.89, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.00, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.00, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.11, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.11, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.22, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.22, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.33, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.33, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.44, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.44, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.55, thresh inequal: lt, the weighted error is 0.200\n",
      "split: dim 1, thresh 1.55, thresh inequal: gt, the weighted error is 0.800\n",
      "split: dim 1, thresh 1.66, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.66, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.77, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.77, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.88, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.88, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 1.99, thresh inequal: lt, the weighted error is 0.400\n",
      "split: dim 1, thresh 1.99, thresh inequal: gt, the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh inequal: lt, the weighted error is 0.600\n",
      "split: dim 1, thresh 2.10, thresh inequal: gt, the weighted error is 0.400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, matrix([[ 0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.mat(np.ones((5,1))/5)\n",
    "buildStump(dataMat,classLabels,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    " def adaBoostTrainDS(dataArr,classLabels,numIt = 40):\n",
    "        weakClassArr = [] # 分类器列表\n",
    "        m = np.shape(dataArr)[0]\n",
    "        D = np.mat(np.ones((m,1))/m) # 初始样本权重矩阵\n",
    "        aggClassEst = np.mat(np.zeros((m,1))) # 计算最终分类结果的矩阵\n",
    "        for i in range(numIt):\n",
    "            bestStump,error,classEst = buildStump(dataArr,classLabels,D) # 寻找当前D情况下的最优DS decision stump\n",
    "            print('D;'+str(D.T))\n",
    "            \n",
    "            alpha = float(0.5*np.log((1.0-error)/max(error,1e-16))) # 计算当前DS的权重并存贮\n",
    "            bestStump['alpha'] = alpha\n",
    "            weakClassArr.append(bestStump)\n",
    "            print('class:'+str(classEst.T))\n",
    "            \n",
    "            expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst)  # np.mat(classLabels).T,classEst 的对应相乘，决定了D是增加还是减小\n",
    "            D = np.multiply(D,np.exp(expon))\n",
    "            D = D/D.sum() # 这里要使用更新权重分子后的D来计算sum，以保证D总和为1，D 本身是一个概率分布向量\n",
    "            \n",
    "            aggClassEst += alpha*classEst # 概率估计值，是概率值，还不是最终分类标签\n",
    "            print('aggClassEst:'+str(aggClassEst.T))\n",
    "            aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m,1))) \n",
    "            # np.sign(aggClassEst) 将概率估计结果转为label\n",
    "            # np.sign(aggClassEst) != np.mat(classLabels).T 产生一个分类准确性 boolean 矩阵\n",
    "            # 与 np.ones((m,1)) 的对应相乘 将 boolean 转换为 1 或 0\n",
    "            errorRate = aggErrors.sum()/m\n",
    "            print('total error: '+str(errorRate))\n",
    "            if errorRate == 0.0 : break\n",
    "        return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D;[[ 0.2  0.2  0.2  0.2  0.2]]\n",
      "class:[[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst:[[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error: 0.2\n",
      "D;[[ 0.5    0.125  0.125  0.125  0.125]]\n",
      "class:[[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst:[[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error: 0.2\n",
      "D;[[ 0.28571429  0.07142857  0.07142857  0.07142857  0.5       ]]\n",
      "class:[[ 1.  1.  1.  1.  1.]]\n",
      "aggClassEst:[[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3},\n",
       " {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'lt', 'thresh': 1.0},\n",
       " {'alpha': 0.8958797346140273,\n",
       "  'dim': 0,\n",
       "  'ineq': 'lt',\n",
       "  'thresh': 0.90000000000000002}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 被分类错误的点在下次的迭代中增加了权重，\n",
    "# 每一次的分类错误率由分类结果和样本权重D决定，上次分类错误的样本权重增大，寻找最优分类器过程中，会使得该样本分类正确的概率增加，\n",
    "# 本次使得上次分类错误的样本分类正确，但也会使得一部分样本上次分类错误，这一次分类不正确\n",
    "# 因此D的不同，导致弱分类器的分类是有侧重的，侧重量由alpha决定\n",
    "# 在每一次的分类结果对于评估最终值的影响程度由分类器权重alpha决定，alpha的值由该分类器错误率决定\n",
    "# 最终将所有分类结果加权求和，就是最终分类结果\n",
    "\n",
    "# 最然弱分类器的分类效果不好，但是权重D，alpha的相互配合导致，每个分类器在这些分类错误点上各有侧重，总有一个能把结果分对\n",
    "classiferArr = adaBoostTrainDS(dataMat,classLabels,9)\n",
    "classiferArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分类结果进行加权求和\n",
    "def adaClassify(dataToClass,classiferArr):\n",
    "    dataMatrix = np.mat(dataToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(len(classiferArr)):\n",
    "        classEst = stumpClasify(dataMatrix,classiferArr[i]['dim'],classiferArr[i]['thresh'],classiferArr[i]['ineq'])\n",
    "        aggClassEst += classiferArr[i]['alpha']*classEst \n",
    "        print(aggClassEst)\n",
    "    return np.sign(aggClassEst)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0,0],classiferArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[ 0.27980789]]\n",
      "[[ 1.17568763]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([1.1,1.1],classiferArr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
