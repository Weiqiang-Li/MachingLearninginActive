{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float((curLine[-1])))\n",
    "    return dataMat,labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义decision stump 单层决策树\n",
    "def stumpClasify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1)) # 返回划分结果矩阵\n",
    "    # 对应数值数据有两种分类方向\n",
    "    # 对于标称数据有等于和不等两种情况（决策树中的情况）\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0 # 平行于坐标轴的直线为阈值，分类，小于阈值的为-1.0 ，\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0 # 大于阈值的为 -1.0 两种分类方向\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 寻找最优单层树\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    labelMatrix = np.mat(classLabels).T\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0 # 步数，决定可能的取值情况\n",
    "    bestStump = {}  # 存储最优单层树\n",
    "    bestClassEst = np.mat(np.zeros((m,1))) # 存储最优单层树的分类误差\n",
    "    minError = np.inf # 初始化误差为无穷大\n",
    "    for i in range(n): # 对于每个维度上的特征\n",
    "        rangeMin = dataMatrix[:,i].min()\n",
    "        rangeMax = dataMatrix[:,i].max()\n",
    "        stepSize = (rangeMax - rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1): # 对于每一个可能取值的步长，这里额外处理取值范围之外的点\n",
    "            for inequal in ['lt','gt']: # 对于该取值下的两种不同分类方向\n",
    "                threshVal = rangeMin + j*stepSize # 计算此时的阈值\n",
    "                predictedVals = stumpClasify(dataMatrix,i,threshVal,inequal)\n",
    "                errArr = np.mat(np.ones((m,1))) # 创建一个错误分类项挑选矩阵\n",
    "                errArr[predictedVals == labelMatrix] = 0 # 挑选\n",
    "                # 这里是评估在相同权重D情况下，最优的单层决策树的评估值，\n",
    "                #也是用于更新alpha以及D的错误率\n",
    "                weightedError = D.T*errArr # 计算加权错误？？？ \n",
    "#                 print(\"split: dim %d, thresh %.2f, thresh inequal: %s, the weighted error is %.3f\"%(i,threshVal,inequal,weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # adaBoost过程\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt = 40):\n",
    "    weakClassArr = [] # 分类器列表\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m,1))/m) # 初始样本权重矩阵\n",
    "    aggClassEst = np.mat(np.zeros((m,1))) # 计算最终分类结果的矩阵\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D) # 寻找当前D情况下的最优DS decision stump\n",
    "#         print('D;'+str(D.T))\n",
    "\n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error,1e-16))) # 计算当前DS的权重并存贮\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "#         print('class:'+str(classEst.T))\n",
    "\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst)  # np.mat(classLabels).T,classEst 的对应相乘，决定了D是增加还是减小\n",
    "        D = np.multiply(D,np.exp(expon))\n",
    "        D = D/D.sum() # 这里要使用更新权重分子后的D来计算sum，以保证D总和为1，D 本身是一个概率分布向量\n",
    "\n",
    "        aggClassEst += alpha*classEst # 概率估计值，是概率值，还不是最终分类标签\n",
    "#         print('aggClassEst:'+str(aggClassEst.T))\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m,1))) \n",
    "        # np.sign(aggClassEst) 将概率估计结果转为label\n",
    "        # np.sign(aggClassEst) != np.mat(classLabels).T 产生一个分类准确性 boolean 矩阵\n",
    "        # 与 np.ones((m,1)) 的对应相乘 将 boolean 转换为 1 或 0\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print('total error: '+str(errorRate))\n",
    "        if errorRate == 0.0 : break\n",
    "    return weakClassArr,aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分类结果进行加权求和\n",
    "def adaClassify(dataToClass,classiferArr):\n",
    "    dataMatrix = np.mat(dataToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(len(classiferArr)):\n",
    "        classEst = stumpClasify(dataMatrix,classiferArr[i]['dim'],classiferArr[i]['thresh'],classiferArr[i]['ineq'])\n",
    "        aggClassEst += classiferArr[i]['alpha']*classEst \n",
    "#         print(aggClassEst)\n",
    "    return np.sign(aggClassEst)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArr,labelArr = loadDataSet('./horseColicTraining2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.284280936455\n",
      "total error: 0.284280936455\n",
      "total error: 0.247491638796\n",
      "total error: 0.247491638796\n",
      "total error: 0.254180602007\n",
      "total error: 0.240802675585\n",
      "total error: 0.240802675585\n",
      "total error: 0.220735785953\n",
      "total error: 0.247491638796\n",
      "total error: 0.230769230769\n",
      "total error: 0.240802675585\n",
      "total error: 0.214046822742\n",
      "total error: 0.227424749164\n",
      "total error: 0.217391304348\n",
      "total error: 0.220735785953\n",
      "total error: 0.217391304348\n",
      "total error: 0.224080267559\n",
      "total error: 0.224080267559\n",
      "total error: 0.230769230769\n",
      "total error: 0.224080267559\n",
      "total error: 0.214046822742\n",
      "total error: 0.207357859532\n",
      "total error: 0.224080267559\n",
      "total error: 0.224080267559\n",
      "total error: 0.214046822742\n",
      "total error: 0.220735785953\n",
      "total error: 0.204013377926\n",
      "total error: 0.207357859532\n",
      "total error: 0.210702341137\n",
      "total error: 0.217391304348\n",
      "total error: 0.210702341137\n",
      "total error: 0.217391304348\n",
      "total error: 0.207357859532\n",
      "total error: 0.210702341137\n",
      "total error: 0.207357859532\n",
      "total error: 0.207357859532\n",
      "total error: 0.197324414716\n",
      "total error: 0.190635451505\n",
      "total error: 0.200668896321\n",
      "total error: 0.197324414716\n",
      "total error: 0.200668896321\n",
      "total error: 0.19397993311\n",
      "total error: 0.19397993311\n",
      "total error: 0.190635451505\n",
      "total error: 0.1872909699\n",
      "total error: 0.190635451505\n",
      "total error: 0.190635451505\n",
      "total error: 0.1872909699\n",
      "total error: 0.19397993311\n",
      "total error: 0.1872909699\n"
     ]
    }
   ],
   "source": [
    "# 由于实际问题的复杂性，所以total error 不一定能收敛到0，一般会稳定到一定的值，此时numItr的设置较为关键\n",
    "# 对于好的数据集，达到最小误差后再增加numItr不会我可没那会有过拟合的问题\n",
    "classifierArr，aggClassEst= adaBoostTrainDS(dataArr,labelArr,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDataArr,testLabelArr = loadDataSet('./horseColicTest2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = adaClassify(testDataArr,classifierArr)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20895522388059701"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在30%缺失数据的情况下\n",
    "errorArr = np.mat(np.ones((67,1)))\n",
    "errorArr[prediction!= np.mat(testLabelArr).T].sum()/67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotROC(predStrengths,classLabels,ax=None,usecolor='blue'):\n",
    "    cur = (1.0,1.0) # 起始坐标\n",
    "    ySum = 0.0 # 统计纵坐标高度，用于计算AUC\n",
    "    numPosClas = np.sum(np.mat(classLabels) == 1.0) # 统计正样本数量\n",
    "    yStep = 1/numPosClas # TPR的步长\n",
    "    xStep = 1/(len(classLabels)-numPosClas) # FPR的步长\n",
    "    sortedIndicies = predStrengths.T.argsort(1) # 指定排序方向，这里是增序排列，所以之后的设置逻辑是设置每一个样本为反\n",
    "    if ax == None:\n",
    "        fig = plt.figure()\n",
    "        fig.clf()\n",
    "        ax = plt.subplot(111)\n",
    "    for index in sortedIndicies.tolist()[0]: #分别设置每一个样本为反\n",
    "        if classLabels[index] == 1.0: # 这里出现一个FN，TPR降低\n",
    "            delX = 0\n",
    "            delY = yStep\n",
    "        else: # 这里出现一个TN FPR降低\n",
    "            delX = xStep\n",
    "            delY = 0\n",
    "            ySum += cur[1]\n",
    "        ax.plot([cur[0],cur[0]-delX],[cur[1],cur[1]-delY],c=usecolor)\n",
    "        cur = (cur[0]-delX,cur[1]-delY)\n",
    "    ax.plot([0,1],[0,1],'b--')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(\"ROC for AdaBoost\")\n",
    "    ax.axis([0,1,0,1])\n",
    "    print('AOC:'+str(ySum*xStep))\n",
    "#     plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.284280936455\n",
      "total error: 0.284280936455\n",
      "total error: 0.247491638796\n",
      "total error: 0.247491638796\n",
      "total error: 0.254180602007\n",
      "total error: 0.240802675585\n",
      "total error: 0.240802675585\n",
      "total error: 0.220735785953\n",
      "total error: 0.247491638796\n",
      "total error: 0.230769230769\n",
      "total error: 0.240802675585\n",
      "total error: 0.214046822742\n",
      "total error: 0.227424749164\n",
      "total error: 0.217391304348\n",
      "total error: 0.220735785953\n",
      "total error: 0.217391304348\n",
      "total error: 0.224080267559\n",
      "total error: 0.224080267559\n",
      "total error: 0.230769230769\n",
      "total error: 0.224080267559\n",
      "total error: 0.214046822742\n",
      "total error: 0.207357859532\n",
      "total error: 0.224080267559\n",
      "total error: 0.224080267559\n",
      "total error: 0.214046822742\n",
      "total error: 0.220735785953\n",
      "total error: 0.204013377926\n",
      "total error: 0.207357859532\n",
      "total error: 0.210702341137\n",
      "total error: 0.217391304348\n",
      "total error: 0.210702341137\n",
      "total error: 0.217391304348\n",
      "total error: 0.207357859532\n",
      "total error: 0.210702341137\n",
      "total error: 0.207357859532\n",
      "total error: 0.207357859532\n",
      "total error: 0.197324414716\n",
      "total error: 0.190635451505\n",
      "total error: 0.200668896321\n",
      "total error: 0.197324414716\n",
      "total error: 0.200668896321\n",
      "total error: 0.19397993311\n",
      "total error: 0.19397993311\n",
      "total error: 0.190635451505\n",
      "total error: 0.1872909699\n",
      "total error: 0.190635451505\n",
      "total error: 0.190635451505\n",
      "total error: 0.1872909699\n",
      "total error: 0.19397993311\n",
      "total error: 0.1872909699\n"
     ]
    }
   ],
   "source": [
    "classifierArr,addClassEst = adaBoostTrainDS(dataArr,labelArr,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOC:0.895394187018\n"
     ]
    }
   ],
   "source": [
    "ax = plotROC(addClassEst,labelArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.284280936455\n",
      "total error: 0.284280936455\n",
      "total error: 0.247491638796\n",
      "total error: 0.247491638796\n",
      "total error: 0.254180602007\n",
      "total error: 0.240802675585\n",
      "total error: 0.240802675585\n",
      "total error: 0.220735785953\n",
      "total error: 0.247491638796\n",
      "total error: 0.230769230769\n"
     ]
    }
   ],
   "source": [
    "classifierArr10,addClassEst10 = adaBoostTrainDS(dataArr,labelArr,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOC:0.858296963506\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhYiIFKVEISIiRSlRiIhIUf8fPrw6wj8yz1gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21f5d267cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax2 = plotROC(addClassEst10,labelArr,ax,'red')\n",
    "plt.show() \n",
    "# 这里的绘图存在一定问题\n",
    "# 注意一旦一张图已经被绘制，重新绘制需要使用别的方法\n",
    "# 两条曲线嵌套，外层的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
